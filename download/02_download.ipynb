{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf082566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 14:15:30,457 - INFO - Downloading to: full_text_downloads\n",
      "2025-10-28 14:15:30,542 - INFO - Your public IP address, (only) used to check entitlements: 128.227.78.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiley TDM Client initialized.\n",
      "Springer Nature API Client initialized.\n",
      "Loaded status for 135835 DOIs from download_checkpoint.json.\n",
      "Loaded 135991 processed DOIs from processed_dois.txt.\n",
      "--- Starting Unified Full-Text Download from doi_list.csv ---\n",
      "--- Saving XML/PDF files to 'full_text_downloads' ---\n",
      "\n",
      "--- Processing Chunk 1 ---\n",
      "--- Finished Chunk 1. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 2 ---\n",
      "--- Finished Chunk 2. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 3 ---\n",
      "--- Finished Chunk 3. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 4 ---\n",
      "--- Finished Chunk 4. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 5 ---\n",
      "--- Finished Chunk 5. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 6 ---\n",
      "--- Finished Chunk 6. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 7 ---\n",
      "--- Finished Chunk 7. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 8 ---\n",
      "--- Finished Chunk 8. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 9 ---\n",
      "--- Finished Chunk 9. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 10 ---\n",
      "--- Finished Chunk 10. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 11 ---\n",
      "--- Finished Chunk 11. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 12 ---\n",
      "--- Finished Chunk 12. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 13 ---\n",
      "--- Finished Chunk 13. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 14 ---\n",
      "--- Finished Chunk 14. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 15 ---\n",
      "--- Finished Chunk 15. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 16 ---\n",
      "--- Finished Chunk 16. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 17 ---\n",
      "--- Finished Chunk 17. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 18 ---\n",
      "--- Finished Chunk 18. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 19 ---\n",
      "--- Finished Chunk 19. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 20 ---\n",
      "--- Finished Chunk 20. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 21 ---\n",
      "--- Finished Chunk 21. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 22 ---\n",
      "--- Finished Chunk 22. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 23 ---\n",
      "--- Finished Chunk 23. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 24 ---\n",
      "--- Finished Chunk 24. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 25 ---\n",
      "--- Finished Chunk 25. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 26 ---\n",
      "--- Finished Chunk 26. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 27 ---\n",
      "--- Finished Chunk 27. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 28 ---\n",
      "--- Finished Chunk 28. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 29 ---\n",
      "--- Finished Chunk 29. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 30 ---\n",
      "--- Finished Chunk 30. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 31 ---\n",
      "--- Finished Chunk 31. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 32 ---\n",
      "--- Finished Chunk 32. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 33 ---\n",
      "--- Finished Chunk 33. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 34 ---\n",
      "--- Finished Chunk 34. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 35 ---\n",
      "--- Finished Chunk 35. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 36 ---\n",
      "--- Finished Chunk 36. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 37 ---\n",
      "--- Finished Chunk 37. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 38 ---\n",
      "--- Finished Chunk 38. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 39 ---\n",
      "--- Finished Chunk 39. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 40 ---\n",
      "--- Finished Chunk 40. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 41 ---\n",
      "--- Finished Chunk 41. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 42 ---\n",
      "--- Finished Chunk 42. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 43 ---\n",
      "--- Finished Chunk 43. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 44 ---\n",
      "--- Finished Chunk 44. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 45 ---\n",
      "--- Finished Chunk 45. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 46 ---\n",
      "--- Finished Chunk 46. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 47 ---\n",
      "--- Finished Chunk 47. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 48 ---\n",
      "--- Finished Chunk 48. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 49 ---\n",
      "--- Finished Chunk 49. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 50 ---\n",
      "--- Finished Chunk 50. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 51 ---\n",
      "--- Finished Chunk 51. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 52 ---\n",
      "--- Finished Chunk 52. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 53 ---\n",
      "--- Finished Chunk 53. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 54 ---\n",
      "--- Finished Chunk 54. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 55 ---\n",
      "--- Finished Chunk 55. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 56 ---\n",
      "--- Finished Chunk 56. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 57 ---\n",
      "--- Finished Chunk 57. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 58 ---\n",
      "--- Finished Chunk 58. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 59 ---\n",
      "--- Finished Chunk 59. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 60 ---\n",
      "--- Finished Chunk 60. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 61 ---\n",
      "--- Finished Chunk 61. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 62 ---\n",
      "--- Finished Chunk 62. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 63 ---\n",
      "--- Finished Chunk 63. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 64 ---\n",
      "--- Finished Chunk 64. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 65 ---\n",
      "--- Finished Chunk 65. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 66 ---\n",
      "--- Finished Chunk 66. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 67 ---\n",
      "--- Finished Chunk 67. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 68 ---\n",
      "--- Finished Chunk 68. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 69 ---\n",
      "--- Finished Chunk 69. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 70 ---\n",
      "--- Finished Chunk 70. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 71 ---\n",
      "--- Finished Chunk 71. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 72 ---\n",
      "--- Finished Chunk 72. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 73 ---\n",
      "--- Finished Chunk 73. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 74 ---\n",
      "--- Finished Chunk 74. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 75 ---\n",
      "--- Finished Chunk 75. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 76 ---\n",
      "--- Finished Chunk 76. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 77 ---\n",
      "--- Finished Chunk 77. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 78 ---\n",
      "--- Finished Chunk 78. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 79 ---\n",
      "--- Finished Chunk 79. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 80 ---\n",
      "--- Finished Chunk 80. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 81 ---\n",
      "--- Finished Chunk 81. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 82 ---\n",
      "--- Finished Chunk 82. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 83 ---\n",
      "--- Finished Chunk 83. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 84 ---\n",
      "--- Finished Chunk 84. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 85 ---\n",
      "--- Finished Chunk 85. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 86 ---\n",
      "--- Finished Chunk 86. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 87 ---\n",
      "--- Finished Chunk 87. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 88 ---\n",
      "--- Finished Chunk 88. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 89 ---\n",
      "--- Finished Chunk 89. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 90 ---\n",
      "--- Finished Chunk 90. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 91 ---\n",
      "--- Finished Chunk 91. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 92 ---\n",
      "--- Finished Chunk 92. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 93 ---\n",
      "--- Finished Chunk 93. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 94 ---\n",
      "--- Finished Chunk 94. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 95 ---\n",
      "--- Finished Chunk 95. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 96 ---\n",
      "--- Finished Chunk 96. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 97 ---\n",
      "--- Finished Chunk 97. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 98 ---\n",
      "--- Finished Chunk 98. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 99 ---\n",
      "--- Finished Chunk 99. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 100 ---\n",
      "--- Finished Chunk 100. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 101 ---\n",
      "--- Finished Chunk 101. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 102 ---\n",
      "--- Finished Chunk 102. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 103 ---\n",
      "--- Finished Chunk 103. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 104 ---\n",
      "--- Finished Chunk 104. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 105 ---\n",
      "--- Finished Chunk 105. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 106 ---\n",
      "--- Finished Chunk 106. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 107 ---\n",
      "--- Finished Chunk 107. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 108 ---\n",
      "--- Finished Chunk 108. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 109 ---\n",
      "--- Finished Chunk 109. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 110 ---\n",
      "--- Finished Chunk 110. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 111 ---\n",
      "--- Finished Chunk 111. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 112 ---\n",
      "--- Finished Chunk 112. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 113 ---\n",
      "--- Finished Chunk 113. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 114 ---\n",
      "--- Finished Chunk 114. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 115 ---\n",
      "--- Finished Chunk 115. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 116 ---\n",
      "--- Finished Chunk 116. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 117 ---\n",
      "--- Finished Chunk 117. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 118 ---\n",
      "--- Finished Chunk 118. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 119 ---\n",
      "--- Finished Chunk 119. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 120 ---\n",
      "--- Finished Chunk 120. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 121 ---\n",
      "--- Finished Chunk 121. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 122 ---\n",
      "--- Finished Chunk 122. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 123 ---\n",
      "--- Finished Chunk 123. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 124 ---\n",
      "--- Finished Chunk 124. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 125 ---\n",
      "--- Finished Chunk 125. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 126 ---\n",
      "--- Finished Chunk 126. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 127 ---\n",
      "--- Finished Chunk 127. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 128 ---\n",
      "--- Finished Chunk 128. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 129 ---\n",
      "--- Finished Chunk 129. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 130 ---\n",
      "--- Finished Chunk 130. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 131 ---\n",
      "--- Finished Chunk 131. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 132 ---\n",
      "--- Finished Chunk 132. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 133 ---\n",
      "--- Finished Chunk 133. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 134 ---\n",
      "--- Finished Chunk 134. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 135 ---\n",
      "--- Finished Chunk 135. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 136 ---\n",
      "--- Finished Chunk 136. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 137 ---\n",
      "--- Finished Chunk 137. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 138 ---\n",
      "--- Finished Chunk 138. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 139 ---\n",
      "--- Finished Chunk 139. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 140 ---\n",
      "--- Finished Chunk 140. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 141 ---\n",
      "--- Finished Chunk 141. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 142 ---\n",
      "--- Finished Chunk 142. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 143 ---\n",
      "--- Finished Chunk 143. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 144 ---\n",
      "--- Finished Chunk 144. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 145 ---\n",
      "--- Finished Chunk 145. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 146 ---\n",
      "--- Finished Chunk 146. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 147 ---\n",
      "--- Finished Chunk 147. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 148 ---\n",
      "--- Finished Chunk 148. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 149 ---\n",
      "--- Finished Chunk 149. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 150 ---\n",
      "--- Finished Chunk 150. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 151 ---\n",
      "--- Finished Chunk 151. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 152 ---\n",
      "--- Finished Chunk 152. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 153 ---\n",
      "--- Finished Chunk 153. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 154 ---\n",
      "--- Finished Chunk 154. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 155 ---\n",
      "--- Finished Chunk 155. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 156 ---\n",
      "--- Finished Chunk 156. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 157 ---\n",
      "--- Finished Chunk 157. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 158 ---\n",
      "--- Finished Chunk 158. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 159 ---\n",
      "--- Finished Chunk 159. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 160 ---\n",
      "--- Finished Chunk 160. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 161 ---\n",
      "--- Finished Chunk 161. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 162 ---\n",
      "--- Finished Chunk 162. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 163 ---\n",
      "--- Finished Chunk 163. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 164 ---\n",
      "--- Finished Chunk 164. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 165 ---\n",
      "--- Finished Chunk 165. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 166 ---\n",
      "--- Finished Chunk 166. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 167 ---\n",
      "--- Finished Chunk 167. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 168 ---\n",
      "--- Finished Chunk 168. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 169 ---\n",
      "--- Finished Chunk 169. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 170 ---\n",
      "--- Finished Chunk 170. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 171 ---\n",
      "--- Finished Chunk 171. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 172 ---\n",
      "--- Finished Chunk 172. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 173 ---\n",
      "--- Finished Chunk 173. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 174 ---\n",
      "--- Finished Chunk 174. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 175 ---\n",
      "--- Finished Chunk 175. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 176 ---\n",
      "--- Finished Chunk 176. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 177 ---\n",
      "--- Finished Chunk 177. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 178 ---\n",
      "--- Finished Chunk 178. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 179 ---\n",
      "--- Finished Chunk 179. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 180 ---\n",
      "--- Finished Chunk 180. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 181 ---\n",
      "--- Finished Chunk 181. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 182 ---\n",
      "--- Finished Chunk 182. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 183 ---\n",
      "--- Finished Chunk 183. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 184 ---\n",
      "--- Finished Chunk 184. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 185 ---\n",
      "--- Finished Chunk 185. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 186 ---\n",
      "--- Finished Chunk 186. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 187 ---\n",
      "--- Finished Chunk 187. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 188 ---\n",
      "--- Finished Chunk 188. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 189 ---\n",
      "--- Finished Chunk 189. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 190 ---\n",
      "--- Finished Chunk 190. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 191 ---\n",
      "--- Finished Chunk 191. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 192 ---\n",
      "--- Finished Chunk 192. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 193 ---\n",
      "--- Finished Chunk 193. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 194 ---\n",
      "--- Finished Chunk 194. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 195 ---\n",
      "--- Finished Chunk 195. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 196 ---\n",
      "--- Finished Chunk 196. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 197 ---\n",
      "--- Finished Chunk 197. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 198 ---\n",
      "--- Finished Chunk 198. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 199 ---\n",
      "--- Finished Chunk 199. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 200 ---\n",
      "--- Finished Chunk 200. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 201 ---\n",
      "--- Finished Chunk 201. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 202 ---\n",
      "--- Finished Chunk 202. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 203 ---\n",
      "--- Finished Chunk 203. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 204 ---\n",
      "--- Finished Chunk 204. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 205 ---\n",
      "--- Finished Chunk 205. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 206 ---\n",
      "--- Finished Chunk 206. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 207 ---\n",
      "--- Finished Chunk 207. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 208 ---\n",
      "--- Finished Chunk 208. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 209 ---\n",
      "--- Finished Chunk 209. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 210 ---\n",
      "--- Finished Chunk 210. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 211 ---\n",
      "--- Finished Chunk 211. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 212 ---\n",
      "--- Finished Chunk 212. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 213 ---\n",
      "--- Finished Chunk 213. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 214 ---\n",
      "--- Finished Chunk 214. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 215 ---\n",
      "--- Finished Chunk 215. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 216 ---\n",
      "--- Finished Chunk 216. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 217 ---\n",
      "--- Finished Chunk 217. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 218 ---\n",
      "--- Finished Chunk 218. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 219 ---\n",
      "--- Finished Chunk 219. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 220 ---\n",
      "--- Finished Chunk 220. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 221 ---\n",
      "--- Finished Chunk 221. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 222 ---\n",
      "--- Finished Chunk 222. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 223 ---\n",
      "--- Finished Chunk 223. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 224 ---\n",
      "--- Finished Chunk 224. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 225 ---\n",
      "--- Finished Chunk 225. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 226 ---\n",
      "--- Finished Chunk 226. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 227 ---\n",
      "--- Finished Chunk 227. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 228 ---\n",
      "--- Finished Chunk 228. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 229 ---\n",
      "--- Finished Chunk 229. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 230 ---\n",
      "--- Finished Chunk 230. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 231 ---\n",
      "--- Finished Chunk 231. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 232 ---\n",
      "--- Finished Chunk 232. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 233 ---\n",
      "--- Finished Chunk 233. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 234 ---\n",
      "--- Finished Chunk 234. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 235 ---\n",
      "--- Finished Chunk 235. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 236 ---\n",
      "--- Finished Chunk 236. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 237 ---\n",
      "--- Finished Chunk 237. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 238 ---\n",
      "--- Finished Chunk 238. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 239 ---\n",
      "--- Finished Chunk 239. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 240 ---\n",
      "--- Finished Chunk 240. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 241 ---\n",
      "--- Finished Chunk 241. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 242 ---\n",
      "--- Finished Chunk 242. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 243 ---\n",
      "--- Finished Chunk 243. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 244 ---\n",
      "--- Finished Chunk 244. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 245 ---\n",
      "--- Finished Chunk 245. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 246 ---\n",
      "--- Finished Chunk 246. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 247 ---\n",
      "--- Finished Chunk 247. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 248 ---\n",
      "--- Finished Chunk 248. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 249 ---\n",
      "--- Finished Chunk 249. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 250 ---\n",
      "--- Finished Chunk 250. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 251 ---\n",
      "--- Finished Chunk 251. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 252 ---\n",
      "--- Finished Chunk 252. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 253 ---\n",
      "--- Finished Chunk 253. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 254 ---\n",
      "--- Finished Chunk 254. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 255 ---\n",
      "--- Finished Chunk 255. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 256 ---\n",
      "--- Finished Chunk 256. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 257 ---\n",
      "--- Finished Chunk 257. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 258 ---\n",
      "--- Finished Chunk 258. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 259 ---\n",
      "--- Finished Chunk 259. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 260 ---\n",
      "--- Finished Chunk 260. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 261 ---\n",
      "--- Finished Chunk 261. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 262 ---\n",
      "--- Finished Chunk 262. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 263 ---\n",
      "--- Finished Chunk 263. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 264 ---\n",
      "--- Finished Chunk 264. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 265 ---\n",
      "--- Finished Chunk 265. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 266 ---\n",
      "--- Finished Chunk 266. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 267 ---\n",
      "--- Finished Chunk 267. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 268 ---\n",
      "--- Finished Chunk 268. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 269 ---\n",
      "--- Finished Chunk 269. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 270 ---\n",
      "--- Finished Chunk 270. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 271 ---\n",
      "--- Finished Chunk 271. Processed 0 new DOIs this session. Checkpoint saved. ---\n",
      "\n",
      "--- Processing Chunk 272 ---\n",
      "Processing DOI: 10.14201/gredos.166181\n",
      "   Unknown publisher for XML API -> Check OA.\n",
      "   Checking OA status / trying PMC XML...\n",
      "   OA but no PMCID (IDConv_NoPMCIDFound).\n",
      "   Attempting Generic OA PDF fallback download...\n",
      "An unexpected error occurred: 'utf-8' codec can't decode byte 0xe1 in position 42: invalid continuation byte\n",
      "Stopping. Run again to resume.\n",
      "\n",
      "Final status log saved to download_checkpoint.json\n",
      "\n",
      "--- Unified Download process finished. ---\n",
      "--- Processed 0 new DOIs in this run. ---\n",
      "--- Check logs and output directory ('full_text_downloads'). ---\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "from wiley_tdm import TDMClient\n",
    "import springernature_api_client.tdm as tdm # <<<--- IMPORT SPRINGER CLIENT MODULE\n",
    "\n",
    "# --- Configuration ---\n",
    "YOUR_EMAIL = \"@ufl.edu\" # Essential for APIs\n",
    "\n",
    "# !!! --- SECURITY WARNING --- !!!\n",
    "# PASTE YOUR KEYS/TOKENS DIRECTLY BELOW (NOT RECOMMENDED FOR SHARING)\n",
    "# SAFER: Replace \"YOUR_KEY...\" with os.environ.get('ENV_VAR_NAME', None)\n",
    "ELSEVIER_API_KEY = \"\"\n",
    "NCBI_API_KEY = \"\"\n",
    "SPRINGER_API_KEY = \"\" # May need \"/YOUR_API_METRIC\" appended\n",
    "WILEY_TDM_TOKEN = \"\"\n",
    "\n",
    "# --- Check if keys seem like placeholders ---\n",
    "if not ELSEVIER_API_KEY or \"PASTE_\" in ELSEVIER_API_KEY: warnings.warn(\"ELSEVIER_API_KEY looks like a placeholder.\")\n",
    "if not NCBI_API_KEY or \"PASTE_\" in NCBI_API_KEY: warnings.warn(\"NCBI_API_KEY looks like a placeholder.\")\n",
    "if not SPRINGER_API_KEY or \"PASTE_\" in SPRINGER_API_KEY: warnings.warn(\"SPRINGER_API_KEY looks like a placeholder.\")\n",
    "if not WILEY_TDM_TOKEN or \"PASTE_\" in WILEY_TDM_TOKEN: warnings.warn(\"WILEY_TDM_TOKEN looks like a placeholder.\")\n",
    "# !!! --- END SECURITY WARNING --- !!!\n",
    "\n",
    "# 1. Input CSV file configuration\n",
    "CSV_FILE_PATH = 'doi_list.csv'\n",
    "DOI_COLUMN_NAME = 'paper_doi'\n",
    "\n",
    "# 2. Output Directory (Unified)\n",
    "OUTPUT_DIR = \"full_text_downloads\"\n",
    "\n",
    "# 3. Files for resuming progress (Unified)\n",
    "CHECKPOINT_FILE = 'download_checkpoint.json'\n",
    "PROCESSED_FILE = 'processed_dois.txt'\n",
    "\n",
    "# 4. CSV Processing Chunk Size\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 5. API Base URLs (Springer URL no longer needed for direct requests)\n",
    "ELSEVIER_BASE_URL = \"https://api.elsevier.com/content/article/doi/\"\n",
    "# SPRINGER_BASE_URL = \"https://api.springernature.com/xmldata/jats\" # Now handled by package\n",
    "NCBI_IDCONV_URL = \"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/\"\n",
    "NCBI_EFETCH_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "UNPAYWALL_URL = \"https://api.unpaywall.org/v2/\"\n",
    "\n",
    "# --- XML Namespaces ---\n",
    "ns_elsevier = {'ce': 'http://www.elsevier.com/xml/common/dtd'}\n",
    "\n",
    "# --- Publisher DOI Prefixes ---\n",
    "ELSEVIER_PREFIXES = ('10.1016',)\n",
    "SPRINGER_NATURE_PREFIXES = ('10.1007', '10.1038', '10.1186', '10.1140', '10.1365', '10.17530', '10.1891', '10.1594')\n",
    "WILEY_PREFIXES = ('10.1002', '10.1111') # Simplified Wiley prefixes\n",
    "\n",
    "# --- Initialize API Clients ---\n",
    "wiley_client = None\n",
    "springer_client = None\n",
    "\n",
    "# Wiley Client Init\n",
    "try:\n",
    "    if WILEY_TDM_TOKEN and \"PASTE_\" not in WILEY_TDM_TOKEN:\n",
    "        os.environ['TDM_API_TOKEN'] = WILEY_TDM_TOKEN\n",
    "        wiley_client = TDMClient(download_dir=OUTPUT_DIR)\n",
    "        print(\"Wiley TDM Client initialized.\")\n",
    "    else:\n",
    "        warnings.warn(\"Wiley TDM Token not set/valid. Wiley PDF download will be skipped.\")\n",
    "except ImportError:\n",
    "     warnings.warn(\"'wiley-tdm' package not installed. Wiley PDF download will be skipped. Run: pip install wiley-tdm\")\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"Could not initialize Wiley TDM Client: {e}. Wiley PDF download will be skipped.\")\n",
    "    wiley_client = None\n",
    "\n",
    "# Springer Client Init\n",
    "try:\n",
    "    if SPRINGER_API_KEY and \"PASTE_\" not in SPRINGER_API_KEY:\n",
    "        # Note: Key might need \"/YOUR_API_METRIC\" appended if auth fails\n",
    "        springer_client = tdm.TDMAPI(api_key=SPRINGER_API_KEY)\n",
    "        print(\"Springer Nature API Client initialized.\")\n",
    "    else:\n",
    "         warnings.warn(\"Springer API Key not set/valid. Springer XML download will be skipped.\")\n",
    "except ImportError:\n",
    "     warnings.warn(\"'springernature-api-client' package not installed. Springer XML download will be skipped. Run: pip install springernature-api-client\")\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"Could not initialize Springer API Client: {e}. Springer XML download will be skipped.\")\n",
    "    springer_client = None\n",
    "\n",
    "# --- Helper Functions (Load/Save Checkpoint, Clean DOI, Sanitize Filename - Minor adjustments) ---\n",
    "def load_checkpoint():\n",
    "    \"\"\"Loads progress from unified checkpoint files.\"\"\"\n",
    "    status_log = {}; processed_dois = set()\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        try:\n",
    "            with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f: status_log = json.load(f)\n",
    "            print(f\"Loaded status for {len(status_log)} DOIs from {CHECKPOINT_FILE}.\")\n",
    "        except json.JSONDecodeError: print(f\"Warning: Could not read {CHECKPOINT_FILE}, starting fresh.\")\n",
    "        except Exception as e: print(f\"Warning: Error loading {CHECKPOINT_FILE}: {e}\")\n",
    "    if os.path.exists(PROCESSED_FILE):\n",
    "        try:\n",
    "            with open(PROCESSED_FILE, 'r', encoding='utf-8') as f: processed_dois = set(line.strip() for line in f if line.strip())\n",
    "            print(f\"Loaded {len(processed_dois)} processed DOIs from {PROCESSED_FILE}.\")\n",
    "        except Exception as e: print(f\"Warning: Could not read {PROCESSED_FILE}: {e}. Starting fresh.\"); processed_dois = set()\n",
    "    return status_log, processed_dois\n",
    "\n",
    "def save_checkpoint(status_log, doi_attempted, status, processed_file_handle):\n",
    "    \"\"\"Saves progress to unified checkpoint files.\"\"\"\n",
    "    status_log[doi_attempted] = status\n",
    "    try:\n",
    "        temp_checkpoint_file = CHECKPOINT_FILE + \".tmp\"\n",
    "        with open(temp_checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(status_log, f, indent=4)\n",
    "        os.replace(temp_checkpoint_file, CHECKPOINT_FILE)\n",
    "    except Exception as e: print(f\"ERROR saving checkpoint {CHECKPOINT_FILE}: {e}\")\n",
    "    try:\n",
    "        processed_file_handle.write(f\"{doi_attempted}\\n\"); processed_file_handle.flush()\n",
    "    except Exception as e: print(f\"ERROR writing to processed {PROCESSED_FILE}: {e}\")\n",
    "\n",
    "def clean_doi(doi_str):\n",
    "    \"\"\"Cleans DOI string, returns None if invalid format.\"\"\"\n",
    "    if pd.isna(doi_str): return None\n",
    "    doi_str = str(doi_str).strip().lower()\n",
    "    if doi_str.startswith('https://doi.org/'): return doi_str[16:]\n",
    "    if doi_str.startswith('http://doi.org/'): return doi_str[15:]\n",
    "    if doi_str.startswith('doi.org/'): return doi_str[8:]\n",
    "    if doi_str.startswith('doi:'): return doi_str[4:].strip()\n",
    "    if doi_str.startswith(('pii ', 's', 'b978')): return None\n",
    "    if doi_str.startswith('10.'): return doi_str\n",
    "    return None\n",
    "\n",
    "def sanitize_filename(name_base, extension):\n",
    "    \"\"\"Creates a safe filename from a base (like DOI) and extension.\"\"\"\n",
    "    if not isinstance(name_base, str) or not name_base.strip(): name_base = \"No_DOI\"\n",
    "    name = name_base.replace('/', '_').replace('\\\\', '_').replace(':', '_').replace('*', '_')\n",
    "    name = name.replace('?', '_').replace('\"', '_').replace('<', '_').replace('>', '_')\n",
    "    name = name.replace('|', '_').replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    name = \"_\".join(filter(None, name.split()))\n",
    "    return name[:150] + extension\n",
    "\n",
    "# --- API Interaction Functions ---\n",
    "\n",
    "def check_unpaywall_for_oa(doi, email):\n",
    "    \"\"\"Checks Unpaywall for OA status and best PDF/landing page URL.\"\"\"\n",
    "    # (No major changes)\n",
    "    if not doi: return {'is_oa': False, 'pdf_url': None, 'landing_url': None, 'status': 'InvalidDOI'}\n",
    "    oa_info = {'is_oa': False, 'pdf_url': None, 'landing_url': None, 'status': 'Unpaywall_Error'}\n",
    "    try:\n",
    "        url = f\"{UNPAYWALL_URL}{quote(doi)}?email={email}\"\n",
    "        response = requests.get(url, timeout=20)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            oa_info['is_oa'] = data.get('is_oa', False)\n",
    "            best_loc = data.get('best_oa_location')\n",
    "            if best_loc:\n",
    "                oa_info['pdf_url'] = best_loc.get('url_for_pdf')\n",
    "                oa_info['landing_url'] = best_loc.get('url_for_landing_page')\n",
    "            oa_info['status'] = 'Paywalled' if not oa_info['is_oa'] else ('OA_Checked')\n",
    "        elif response.status_code == 404: oa_info['status'] = 'Unpaywall_NotFound'\n",
    "        elif response.status_code == 429: oa_info['status'] = 'Unpaywall_RateLimit'; print(f\"   Unpaywall rate limit (429). Sleeping 10s...\"); time.sleep(10)\n",
    "        else: oa_info['status'] = f'Unpaywall_Error_{response.status_code}'; print(f\"   Unpaywall Error {response.status_code} for {doi}.\")\n",
    "    except requests.exceptions.Timeout: oa_info['status'] = 'Unpaywall_Timeout'; print(f\"   Unpaywall Timeout for {doi}.\")\n",
    "    except requests.exceptions.RequestException as e: oa_info['status'] = 'Unpaywall_NetworkError'; print(f\"   Unpaywall Network Error for {doi}: {e}\")\n",
    "    finally: time.sleep(0.1)\n",
    "    return oa_info\n",
    "\n",
    "def get_pmcid_from_doi(doi, email, api_key=None):\n",
    "    \"\"\"Gets PMCID from DOI using NCBI ID Converter.\"\"\"\n",
    "    # (No major changes)\n",
    "    if not doi: return None, \"InvalidDOI\"\n",
    "    params = {'ids': doi, 'format': 'json', 'tool': 'UF_PhD_Script', 'email': email}\n",
    "    if api_key and \"YOUR_\" not in api_key: params['api_key'] = api_key\n",
    "    status = \"IDConv_Error\"; pmcid = None\n",
    "    try:\n",
    "        response = requests.get(NCBI_IDCONV_URL, params=params, timeout=15)\n",
    "        if response.status_code == 400: status = \"IDConv_NotFound\"\n",
    "        elif response.status_code == 429: status = \"IDConv_RateLimit\"; print(\"   NCBI IDConv rate limit (429). Sleeping 10s...\"); time.sleep(10)\n",
    "        else:\n",
    "            response.raise_for_status(); data = response.json()\n",
    "            for record in data.get('records', []):\n",
    "                if record.get('doi', '').lower() == doi.lower() and 'pmcid' in record: pmcid = record['pmcid']; status = \"Success_GotPMCID\"; break\n",
    "            if not pmcid: status = \"IDConv_NoPMCIDFound\"\n",
    "    except requests.exceptions.HTTPError as e: print(f\"   NCBI IDConv HTTP Error {e.response.status_code} for {doi}\"); status = f\"IDConv_HTTPError_{e.response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e: print(f\"   NCBI IDConv Network Error for {doi}: {e}\"); status = \"IDConv_NetworkError\"\n",
    "    finally: time.sleep(0.15 if api_key and \"YOUR_\" not in api_key else 0.4)\n",
    "    return pmcid, status\n",
    "\n",
    "def download_pmc_xml(pmcid, email, api_key=None):\n",
    "    \"\"\"Downloads and validates XML from PMC using EFetch.\"\"\"\n",
    "    # (No major changes)\n",
    "    if not pmcid: return None, \"No PMCID\"\n",
    "    params = {'db': 'pmc', 'id': pmcid, 'retmode': 'xml', 'rettype': 'full', 'tool': 'UF_PhD_Script', 'email': email}\n",
    "    if api_key and \"YOUR_\" not in api_key: params['api_key'] = api_key\n",
    "    xml_content = None; status = \"PMC_FetchError_Unknown\"\n",
    "    try:\n",
    "        response = requests.get(NCBI_EFETCH_URL, params=params, timeout=60)\n",
    "        if response.status_code == 429: print(\"   NCBI EFetch rate limit (429). Sleeping 60s...\"); time.sleep(60); status = \"PMC_RateLimit\"; return None, status\n",
    "        response.raise_for_status()\n",
    "        content_type = response.headers.get('Content-Type', '').lower()\n",
    "        if 'xml' not in content_type: status = f\"PMC_BadContentType_{content_type[:30]}\"\n",
    "        else:\n",
    "            try:\n",
    "                root = ET.fromstring(response.content)\n",
    "                if root.tag == 'pmc-articleset' or root.find('.//article') is not None or root.tag == 'article': xml_content = response.content; status = \"Success_PMC_XML\"\n",
    "                else: status = \"PMC_InvalidXML_Structure\"\n",
    "            except ET.ParseError: status = \"PMC_InvalidXML_ParseError\"\n",
    "    except requests.exceptions.HTTPError as e: status = f\"PMC_HTTPError_{e.response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e: status = f\"PMC_NetworkError: {e}\"\n",
    "    finally: time.sleep(0.15 if api_key and \"YOUR_\" not in api_key else 0.4)\n",
    "    return xml_content, status\n",
    "\n",
    "\n",
    "def download_elsevier_xml(doi, api_key):\n",
    "    \"\"\"Downloads and validates XML from Elsevier API.\"\"\"\n",
    "    # (No major changes)\n",
    "    if not doi: return None, \"InvalidDOI\"\n",
    "    if \"YOUR_\" in api_key: return None, \"InvalidAPIKey_Elsevier\"\n",
    "    headers = {\"Accept\": \"text/xml\", \"X-ELS-APIKey\": api_key}; url = ELSEVIER_BASE_URL + quote(doi)\n",
    "    xml_content = None; status = \"Elsevier_Error_Unknown\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=45)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                root = ET.fromstring(response.content)\n",
    "                first_paragraph = root.find('.//ce:para', namespaces=ns_elsevier)\n",
    "                if first_paragraph is not None: xml_content = response.content; status = \"Success_Elsevier_XML\"\n",
    "                else: status = \"Elsevier_MetadataOnly\"\n",
    "            except ET.ParseError: status = \"Elsevier_InvalidXML\"\n",
    "        elif response.status_code == 401: status = \"Elsevier_AuthError\"; print(\"!! Elsevier Auth Error - Check Key/VPN !!\")\n",
    "        elif response.status_code == 403: status = \"Elsevier_Forbidden\"\n",
    "        elif response.status_code == 404: status = \"Elsevier_NotFound\"\n",
    "        elif response.status_code == 429: status = \"Elsevier_RateLimit\"; print(\"   Elsevier rate limit (429). Sleeping 5 mins...\"); time.sleep(300)\n",
    "        else: status = f\"Elsevier_HTTPError_{response.status_code}\"\n",
    "    except requests.exceptions.Timeout: status = \"Elsevier_Timeout\"\n",
    "    except requests.exceptions.RequestException as e: status = f\"Elsevier_NetworkError: {e}\"\n",
    "    finally: time.sleep(1) # Elsevier allows 10/sec, 1s sleep is safe\n",
    "    return xml_content, status\n",
    "\n",
    "# --- UPDATED: Springer Nature XML Download via Package ---\n",
    "# --- UPDATED: Springer Nature XML Download via Package ---\n",
    "def download_springer_xml_package(doi, client):\n",
    "    \"\"\"Downloads and validates XML from Springer Nature using official package.\"\"\"\n",
    "    if not client: return None, \"SpringerClient_NotInitialized\"\n",
    "    if not doi: return None, \"InvalidDOI\"\n",
    "    # Check original key variable for placeholder\n",
    "    if not SPRINGER_API_KEY or \"PASTE_\" in SPRINGER_API_KEY:\n",
    "        return None, \"InvalidAPIKey_Springer\"\n",
    "\n",
    "    xml_content = None; status = \"SpringerPkg_Error_Unknown\"\n",
    "    try:\n",
    "        # Use the client's search method to get the raw response object\n",
    "        # Pass p=1 to limit results (should only be 1 for a DOI)\n",
    "        response = client.search(q=f'doi:{doi}', p=1, s=1) # Get raw requests.Response\n",
    "\n",
    "        # Access status code from the underlying requests response\n",
    "        response_status_code = getattr(response, 'status_code', None)\n",
    "\n",
    "        if response_status_code == 200:\n",
    "            content_type = getattr(response, 'headers', {}).get('Content-Type', '').lower()\n",
    "            if 'xml' in content_type:\n",
    "                raw_xml_candidate = getattr(response, 'content', None) # Get bytes content\n",
    "                if raw_xml_candidate:\n",
    "                    try:\n",
    "                        root = ET.fromstring(raw_xml_candidate)\n",
    "                        body_tag = root.find('.//{*}body'); p_tag = root.find('.//{*}p')\n",
    "                        if body_tag is not None or p_tag is not None:\n",
    "                            xml_content = raw_xml_candidate # Keep as bytes\n",
    "                            status = \"Success_SpringerPkg_XML\"\n",
    "                        else:\n",
    "                            status = \"SpringerPkg_MetadataOrAbstractOnly\"\n",
    "                    except ET.ParseError:\n",
    "                        status = \"SpringerPkg_InvalidXMLResponse\"\n",
    "                else:\n",
    "                    status = \"SpringerPkg_EmptyResponseContent\"\n",
    "            else:\n",
    "                status = f\"SpringerPkg_BadContentType_{content_type[:30]}\"\n",
    "        elif response_status_code == 401 or response_status_code == 403:\n",
    "            status = f\"SpringerPkg_AuthError_{response_status_code}\"\n",
    "            print(f\"!! Springer Auth Error ({response_status_code}) via Package - Check Key/Metric !!\")\n",
    "        elif response_status_code == 404:\n",
    "            status = \"SpringerPkg_NotFound\"\n",
    "        elif response_status_code == 429:\n",
    "            status = \"SpringerPkg_RateLimit\"; print(\"   Springer rate limit (429) via Package. Sleeping 60s...\"); time.sleep(60)\n",
    "        elif response_status_code is not None: # Other HTTP errors\n",
    "            status = f\"SpringerPkg_HTTPError_{response_status_code}\"\n",
    "        else:\n",
    "            # If we couldn't get a status code (caught below)\n",
    "            status = \"SpringerPkg_NoResponseStatus\"\n",
    "\n",
    "    # Catch specific requests errors potentially raised by the package\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        status_code = e.response.status_code\n",
    "        if status_code == 429: status = \"SpringerPkg_RateLimit\"; print(\"   Springer rate limit (429) via Package. Sleeping 60s...\"); time.sleep(60)\n",
    "        elif status_code == 401 or status_code == 403: status = f\"SpringerPkg_AuthError_{status_code}\"; print(f\"!! Springer Auth Error ({status_code}) via Package - Check Key/Metric !!\")\n",
    "        elif status_code == 404: status = \"SpringerPkg_NotFound\"\n",
    "        else: status = f\"SpringerPkg_HTTPError_{status_code}\"\n",
    "        print(f\"   Springer Package HTTP Error: {e}\")\n",
    "    except requests.exceptions.Timeout: status = \"SpringerPkg_Timeout\"; print(f\"   Springer Package Timeout for {doi}\")\n",
    "    except requests.exceptions.RequestException as e: status = f\"SpringerPkg_NetworkError\"; print(f\"   Springer Package Network Error: {e}\")\n",
    "    # Catch other potential errors, including from the package itself if needed\n",
    "    except Exception as e: status = f\"SpringerPkg_UnexpectedError: {type(e).__name__}\"; print(f\"   Unexpected Error using Springer package for {doi}: {e}\")\n",
    "    finally:\n",
    "        # Adhere to Premium Full Text API rate limit: 200/min (~3.3/sec). Sleep 0.4s.\n",
    "        time.sleep(1)\n",
    "    return xml_content, status\n",
    "\n",
    "\n",
    "# --- Wiley PDF Download Function ---\n",
    "def download_wiley_pdf_client(doi, client, output_path):\n",
    "    \"\"\" Attempts to download PDF using the initialized wiley-tdm client. \"\"\"\n",
    "    if not client: return False, \"WileyClient_NotInitialized\"\n",
    "    if not doi: return False, \"InvalidDOI\"\n",
    "    # Check the original token variable, not env var here\n",
    "    if not WILEY_TDM_TOKEN or \"PASTE_\" in WILEY_TDM_TOKEN: return False, \"InvalidAPIKey_Wiley\"\n",
    "\n",
    "    status = \"Wiley_Error_Unknown\"\n",
    "    pdf_saved = False\n",
    "    try:\n",
    "        print(f\"   Attempting Wiley PDF download via TDM Client...\")\n",
    "        # Client handles filename and saving to client.download_dir (OUTPUT_DIR)\n",
    "        client.download_pdf(doi)\n",
    "\n",
    "        # Infer filename based on DOI and check existence/size\n",
    "        # The client might escape DOIs differently, adjust if needed\n",
    "        sanitized_doi_base = sanitize_filename(doi, \"\") # Get base name without extension\n",
    "        expected_filename = f\"{sanitized_doi_base}.pdf\" # Standard PDF extension\n",
    "        expected_filepath = os.path.join(client.download_dir, expected_filename)\n",
    "\n",
    "        time.sleep(1.5) # Allow slightly more time for write operation\n",
    "\n",
    "        if os.path.exists(expected_filepath) and os.path.getsize(expected_filepath) > 1000:\n",
    "             pdf_saved = True; status = \"Success_Wiley_PDF\"\n",
    "             print(f\"    SUCCESS: Wiley TDM Client saved PDF for {doi}\")\n",
    "             # Optional: Rename if client uses unexpected naming, e.g. os.rename(...)\n",
    "        else:\n",
    "            # Infer failure. Client's own logging should have details.\n",
    "            status = \"Wiley_PDFFail_ClientDidNotSave\"\n",
    "            if os.path.exists(expected_filepath): os.remove(expected_filepath) # Clean up empty file\n",
    "            print(f\"   Wiley TDM Client did not save PDF for {doi}. Check logs/access.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        status = f\"Wiley_ClientError: {type(e).__name__}\"\n",
    "        print(f\"   Error using Wiley TDM Client for {doi}: {e}\")\n",
    "    finally:\n",
    "         time.sleep(1) # Pause after Wiley attempt\n",
    "    return pdf_saved, status\n",
    "\n",
    "\n",
    "# --- Unpaywall PDF Fallback Function ---\n",
    "def download_pdf_unpaywall(pdf_url, filepath, email):\n",
    "    \"\"\"Downloads a PDF from a generic Unpaywall URL.\"\"\"\n",
    "    # (Using the slightly improved version from previous step)\n",
    "    if not pdf_url: return False, \"NoPDF_URL\"\n",
    "    try:\n",
    "        headers = {'User-Agent': f'UF_PhD_Script/1.0 (mailto:{email})', 'Accept': 'application/pdf, */*'}\n",
    "        response = requests.get(pdf_url, headers=headers, stream=True, timeout=90, allow_redirects=True)\n",
    "        content_type = response.headers.get('Content-Type', '').lower()\n",
    "        if response.status_code >= 200 and response.status_code < 300:\n",
    "            if 'pdf' in content_type or 'application/octet-stream' in content_type or not content_type:\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=16384):\n",
    "                        if chunk: f.write(chunk)\n",
    "                if os.path.getsize(filepath) > 1000: return True, \"Success_OA_PDF\"\n",
    "                else: os.remove(filepath); return False, \"OA_PDFFail_EmptyFile\"\n",
    "            else: return False, f\"OA_PDFFail_NotPDF_{content_type[:30]}\"\n",
    "        elif response.status_code == 429: return False, \"OA_PDFFail_RateLimit\"\n",
    "        else: return False, f\"OA_PDFFail_HTTP_{response.status_code}\"\n",
    "    except requests.exceptions.Timeout: return False, \"OA_PDFFail_Timeout\"\n",
    "    except requests.exceptions.TooManyRedirects: return False, \"OA_PDFFail_RedirectLoop\"\n",
    "    except requests.exceptions.RequestException: return False, f\"OA_PDFFail_NetworkError\"\n",
    "    finally: time.sleep(0.5)\n",
    "\n",
    "# --- Main Script Logic ---\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) # Unified output directory\n",
    "status_log, processed_dois = load_checkpoint()\n",
    "total_processed_in_session = 0\n",
    "stop_processing = False\n",
    "\n",
    "print(f\"--- Starting Unified Full-Text Download from {CSV_FILE_PATH} ---\")\n",
    "print(f\"--- Saving XML/PDF files to '{OUTPUT_DIR}' ---\")\n",
    "\n",
    "try:\n",
    "    with open(PROCESSED_FILE, 'a', buffering=1, encoding='utf-8') as processed_file:\n",
    "        chunk_iterator = pd.read_csv(CSV_FILE_PATH, chunksize=CHUNK_SIZE, usecols=[DOI_COLUMN_NAME], dtype={DOI_COLUMN_NAME: str}, low_memory=False)\n",
    "\n",
    "        for chunk_num, chunk in enumerate(chunk_iterator):\n",
    "            if stop_processing: break\n",
    "            print(f\"\\n--- Processing Chunk {chunk_num + 1} ---\")\n",
    "            dois_in_chunk = chunk[DOI_COLUMN_NAME].tolist()\n",
    "\n",
    "            for original_doi_str in dois_in_chunk:\n",
    "                if stop_processing: break\n",
    "                status = \"Unknown Error\"; xml_saved = False; pdf_saved = False; oa_info = {}\n",
    "\n",
    "                # --- RESUME ---\n",
    "                if pd.isna(original_doi_str) or not str(original_doi_str).strip(): continue\n",
    "                original_doi_str = str(original_doi_str).strip()\n",
    "                if original_doi_str in processed_dois: continue\n",
    "\n",
    "                # --- Clean DOI ---\n",
    "                doi = clean_doi(original_doi_str)\n",
    "                if not doi: status = \"InvalidDOIFormat\"\n",
    "                else:\n",
    "                    print(f\"Processing DOI: {doi}\")\n",
    "                    # --- Define potential output paths ---\n",
    "                    xml_filename = sanitize_filename(doi, \".xml\")\n",
    "                    xml_output_path = os.path.join(OUTPUT_DIR, xml_filename)\n",
    "                    pdf_filename = sanitize_filename(doi, \".pdf\")\n",
    "                    pdf_output_path = os.path.join(OUTPUT_DIR, pdf_filename)\n",
    "\n",
    "                    # --- 0. Check if File Already Exists ---\n",
    "                    if os.path.exists(xml_output_path):\n",
    "                        print(f\"   Skipping: XML file already exists for {doi}\")\n",
    "                        status = \"Success_AlreadyExisted_XML\"; xml_saved = True\n",
    "                    elif os.path.exists(pdf_output_path):\n",
    "                        print(f\"   Skipping: PDF file already exists for {doi}\")\n",
    "                        status = \"Success_AlreadyExisted_PDF\"; pdf_saved = True\n",
    "\n",
    "\n",
    "                    # --- 1. Try Publisher XML APIs (if no file exists) ---\n",
    "                    if not xml_saved and not pdf_saved:\n",
    "                        publisher_attempted = False # Flag if we tried a specific publisher API\n",
    "\n",
    "                        # --- Elsevier ---\n",
    "                        if doi.startswith(ELSEVIER_PREFIXES):\n",
    "                            publisher_attempted = True\n",
    "                            print(f\"   DOI is Elsevier -> Try XML API...\")\n",
    "                            xml_content, status = download_elsevier_xml(doi, ELSEVIER_API_KEY)\n",
    "                            if xml_content:\n",
    "                                try:\n",
    "                                    with open(xml_output_path, 'wb') as f: f.write(xml_content)\n",
    "                                    print(f\"    SUCCESS: Saved Elsevier XML\"); xml_saved = True\n",
    "                                except Exception as write_e: print(f\"   ERROR writing Elsevier XML: {write_e}\"); status = \"Elsevier_FileWriteError\"\n",
    "                            elif status == \"Elsevier_AuthError\": stop_processing = True\n",
    "                            else: print(f\"   Elsevier Status: {status}\")\n",
    "\n",
    "                        # --- Springer Nature ---\n",
    "                        elif any(doi.startswith(prefix) for prefix in SPRINGER_NATURE_PREFIXES):\n",
    "                            publisher_attempted = True\n",
    "                            print(f\"   DOI is Springer -> Try XML API Package...\")\n",
    "                            if springer_client: # Check if client initialized\n",
    "                                xml_content, status = download_springer_xml_package(doi, springer_client)\n",
    "                                if xml_content:\n",
    "                                    try:\n",
    "                                        with open(xml_output_path, 'wb') as f: f.write(xml_content)\n",
    "                                        print(f\"    SUCCESS: Saved Springer XML\"); xml_saved = True\n",
    "                                    except Exception as write_e: print(f\"   ERROR writing Springer XML: {write_e}\"); status = \"SpringerPkg_FileWriteError\"\n",
    "                                elif status == \"SpringerPkg_AuthError\": print(\"!! Check Springer API Key/Metric !!\") # Don't stop\n",
    "                                else: print(f\"   Springer Package Status: {status}\")\n",
    "                            else:\n",
    "                                 status = \"SpringerClient_NotInitialized\"\n",
    "                                 print(\"   Skipping Springer XML: Client not initialized.\")\n",
    "\n",
    "\n",
    "                        # --- Add other PUBLISHER XML API checks here ---\n",
    "                        # elif any(doi.startswith(prefix) for prefix in SOME_OTHER_XML_API_PREFIXES): ...\n",
    "\n",
    "                        # If no specific publisher XML API was attempted or matched\n",
    "                        if not publisher_attempted:\n",
    "                            status = \"UnknownPublisherXML_TryOA\"; print(f\"   Unknown publisher for XML API -> Check OA.\")\n",
    "\n",
    "\n",
    "                    # --- 2. Try Open Access XML via PMC (if XML not found yet) ---\n",
    "                    if not xml_saved and not pdf_saved and not stop_processing:\n",
    "                        # Only check OA if needed (i.e., publisher attempt failed or wasn't applicable)\n",
    "                        print(f\"   Checking OA status / trying PMC XML...\")\n",
    "                        oa_info = check_unpaywall_for_oa(doi, YOUR_EMAIL)\n",
    "                        if oa_info.get('is_oa', False):\n",
    "                            pmcid, id_conv_status = get_pmcid_from_doi(doi, YOUR_EMAIL, NCBI_API_KEY)\n",
    "                            if pmcid:\n",
    "                                xml_content, pmc_status = download_pmc_xml(pmcid, YOUR_EMAIL, NCBI_API_KEY)\n",
    "                                if xml_content:\n",
    "                                    try:\n",
    "                                        with open(xml_output_path, 'wb') as f: f.write(xml_content)\n",
    "                                        print(f\"    SUCCESS: Saved PMC XML\"); xml_saved = True; status = pmc_status\n",
    "                                    except Exception as write_e: print(f\"   ERROR writing PMC XML: {write_e}\"); status = \"PMC_FileWriteError\"\n",
    "                                else: status = pmc_status; print(f\"   PMC Status: {status}\") # Use PMC failure status\n",
    "                            else:\n",
    "                                status = f\"OA_NoPMCID_{id_conv_status}\"\n",
    "                                print(f\"   OA but no PMCID ({id_conv_status}).\")\n",
    "                                # Proceed to check Wiley/Unpaywall PDF\n",
    "                        else:\n",
    "                            status = oa_info.get('status', 'Paywalled_CheckFailed')\n",
    "                            print(f\"   Not OA according to Unpaywall (Status: {status}).\")\n",
    "\n",
    "\n",
    "                    # --- 3. Try Wiley PDF (if NO XML found AND it's a Wiley DOI) ---\n",
    "                    # Placed after OA XML attempt. Requires VPN/Subscription if not OA.\n",
    "                    is_wiley = any(doi.startswith(prefix) for prefix in WILEY_PREFIXES)\n",
    "                    if not xml_saved and not pdf_saved and not stop_processing and is_wiley:\n",
    "                         if wiley_client:\n",
    "                              print(f\"   DOI is Wiley -> Try PDF via Wiley TDM Client...\")\n",
    "                              # Note: This attempts download even if Unpaywall said Paywalled,\n",
    "                              # relying on institutional access via VPN + Token.\n",
    "                              pdf_saved_flag, pdf_status = download_wiley_pdf_client(doi, wiley_client, pdf_output_path)\n",
    "                              status = pdf_status # Update status with Wiley outcome\n",
    "                              if pdf_saved_flag: pdf_saved = True\n",
    "                              else: print(f\"   Wiley PDF download failed. Status: {status}\")\n",
    "                         else:\n",
    "                              # Only log Wiley was skipped if it wasn't already marked as OA but failed PMC etc.\n",
    "                              if status not in [\"Success_AlreadyExisted_XML\", \"Success_AlreadyExisted_PDF\"] and not status.startswith(\"Success\"):\n",
    "                                   status = \"WileySkipped_NoClient\"\n",
    "                                   print(\"   Skipping Wiley PDF: Client not initialized.\")\n",
    "\n",
    "\n",
    "                    # --- 4. Try Generic Unpaywall OA PDF Fallback (if NO file saved AND Unpaywall found OA or gave URL) ---\n",
    "                    if not xml_saved and not pdf_saved and not stop_processing:\n",
    "                        # Need oa_info from step 2, fetch if we skipped step 2 or step 3 was Wiley\n",
    "                        if not oa_info or is_wiley: # Re-check if we didn't check before or if Wiley was attempted\n",
    "                             print(f\"   Re-checking Unpaywall for PDF fallback link...\")\n",
    "                             oa_info = check_unpaywall_for_oa(doi, YOUR_EMAIL)\n",
    "\n",
    "                        # Try PDF ONLY if Unpaywall says OA OR if it gave a PDF URL\n",
    "                        # AND we haven't already succeeded with Wiley PDF\n",
    "                        if oa_info.get('is_oa', False) or oa_info.get('pdf_url'):\n",
    "                            pdf_url = oa_info.get('pdf_url')\n",
    "                            if pdf_url:\n",
    "                                print(f\"   Attempting Generic OA PDF fallback download...\")\n",
    "                                pdf_saved_flag, pdf_status = download_pdf_unpaywall(pdf_url, pdf_output_path, YOUR_EMAIL)\n",
    "                                status = pdf_status # Update main status\n",
    "                                if pdf_saved_flag: print(f\"    SUCCESS: Saved Generic OA PDF fallback\"); pdf_saved = True\n",
    "                                else: print(f\"   Generic PDF download failed. Status: {status}\")\n",
    "                            else:\n",
    "                                # Still considered OA by Unpaywall, but no PDF link found\n",
    "                                if status.startswith(\"OA_\") or status == \"OA_Checked\" or status == \"UnknownPublisherXML_TryOA\":\n",
    "                                     status = \"OA_NoPDFLink\" # Set specific status\n",
    "                                # Avoid overwriting Publisher/PMC fail statuses if PDF wasn't applicable\n",
    "                                print(f\"   OA but no Generic PDF link found. Final Status: {status}\")\n",
    "                        # If not OA and no PDF URL, status should be set (Paywalled/Error)\n",
    "\n",
    "\n",
    "                    # Final status cleanup if nothing worked\n",
    "                    if not xml_saved and not pdf_saved and status in [\"Unknown Error\", \"UnknownPublisherXML_TryOA\", \"OA_Checked\"]:\n",
    "                         if oa_info and not oa_info.get('is_oa', False): status = oa_info.get('status', 'Paywalled_Final')\n",
    "                         elif oa_info and oa_info.get('is_oa', False): status = \"OA_DownloadFailed\"\n",
    "                         else: status = \"DownloadFailed_Unknown\"\n",
    "\n",
    "\n",
    "                # --- Save Progress ---\n",
    "                processed_dois.add(original_doi_str)\n",
    "                save_checkpoint(status_log, original_doi_str, status, processed_file)\n",
    "                total_processed_in_session += 1\n",
    "                if stop_processing: break # Exit inner loop\n",
    "\n",
    "            print(f\"--- Finished Chunk {chunk_num + 1}. Processed {total_processed_in_session} new DOIs this session. Checkpoint saved. ---\")\n",
    "\n",
    "except FileNotFoundError: print(f\"ERROR: Cannot find input CSV '{CSV_FILE_PATH}'.\")\n",
    "except KeyError: print(f\"ERROR: Column '{DOI_COLUMN_NAME}' not found in '{CSV_FILE_PATH}'.\")\n",
    "except ImportError as e: print(f\"ERROR: Missing library. Please install required packages (e.g., pip install requests pandas wiley-tdm springernature-api-client). Details: {e}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred: {e}\\nStopping. Run again to resume.\")\n",
    "finally:\n",
    "    # Final save\n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f: json.dump(status_log, f, indent=4)\n",
    "        print(f\"\\nFinal status log saved to {CHECKPOINT_FILE}\")\n",
    "    except Exception as e: print(f\"ERROR saving final checkpoint {CHECKPOINT_FILE}: {e}\")\n",
    "    print(f\"\\n--- Unified Download process finished. ---\")\n",
    "    print(f\"--- Processed {total_processed_in_session} new DOIs in this run. ---\")\n",
    "    print(f\"--- Check logs and output directory ('{OUTPUT_DIR}'). ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEL",
   "language": "EEL",
   "name": "eel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
